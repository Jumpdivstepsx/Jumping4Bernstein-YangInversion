#include "macros_neon.h"
#include "polymul_neon.h"
#include <arm_neon.h>


//(x^8-1) = twiddle permute butterfly
int16x8_t twiddle_p_64 = {
    72,    -3430,     3219,     3590,      363,     2020,      591,    -1835
};
//(x^8+1)
int16x8_t twiddle_n_64 = {
    2232,     -864,     681,     -788,    -2047,     1336,      -19,    -2325
};
//(x^8-1)
int16x8_t itwiddle_p_64 = {
    -1837,      589,     2018,     361,     3588,     3217,    -3432,       70
};
//(x^8+1)
int16x8_t itwiddle_n_64 = {
    -2325,      -19,     1336,    -2047,     -788,      681,     -864,     2232
};

//twist_table: 0-15; nR_overq2: 16-31
int16x8_t twist64[32] = { 
    {4051, 1654, 171, 2996, 2930, 2418, 2898, 2448}, {143, 3551, 3390, 1222, 4051, 171, 2930, 2898}, {1654, 2930, 2448, 4170, 3390, 576, 171, 2418}, {4170, 839, 1654, 2418, 143, 3390, 4051, 2930}, {171, 2448, 975, 4051, 2418, 4170, 1222, 2996}, {3551, 4051, 2898, 975, 1654, 2448, 3390, 171}, {2996, 4170, 4051, 2448, 839, 2930, 3551, 1654}, {975, 2996, 3551, 171, 4170, 1654, 143, 4051}, {2930, 3390, 2418, 839, 2898, 1222, 2448, 576}, {3390, 2898, 576, 143, 171, 975, 2418, 1222}, {2418, 576, 4170, 2930, 1222, 143, 2996, 839}, {839, 143, 2930, 576, 3551, 2898, 1654, 3390}, {2898, 171, 1222, 3551, 2448, 2996, 576, 975}, {1222, 975, 143, 2898, 2996, 4051, 839, 3551}, {2448, 2418, 2996, 1654, 576, 839, 975, 4170}, {576, 1222, 839, 3390, 975, 3551, 4170, 143}, {28914, 11805, 1221, 21384, 20913, 17258, 20684, 17472}, {1021, 25345, 24196, 8722, 28914, 1221, 20913, 20684}, {11805, 20913, 17472, 29763, 24196, 4111, 1221, 17258}, {29763, 5988, 11805, 17258, 1021, 24196, 28914, 20913}, {1221, 17472, 6959, 28914, 17258, 29763, 8722, 21384}, {25345, 28914, 20684, 6959, 11805, 17472, 24196, 1221}, {21384, 29763, 28914, 17472, 5988, 20913, 25345, 11805}, {6959, 21384, 25345, 1221, 29763, 11805, 1021, 28914}, {20913, 24196, 17258, 5988, 20684, 8722, 17472, 4111}, {24196, 20684, 4111, 1021, 1221, 6959, 17258, 8722}, {17258, 4111, 29763, 20913, 8722, 1021, 21384, 5988}, {5988, 1021, 20913, 4111, 25345, 20684, 11805, 24196}, {20684, 1221, 8722, 25345, 17472, 21384, 4111, 6959}, {8722, 6959, 1021, 20684, 21384, 28914, 5988, 25345}, {17472, 17258, 21384, 11805, 4111, 5988, 6959, 29763}, {4111, 8722, 5988, 24196, 6959, 25345, 29763, 1021}
};
//twist_inv_table
int16x8_t twist64_inv[32] = {
    {574, 612, 3020, 2900, 3028, 749, 3486, 2709}, {144, 3653, 3687, 3338, 574, 3020, 3028, 3486}, {612, 3028, 2709, 2601, 3687, 3479, 3020, 749}, {2601, 4331, 612, 749, 144, 3687, 574, 3028}, {3020, 2709, 3143, 574, 749, 2601, 3338, 2900}, {3653, 574, 3486, 3143, 612, 2709, 3687, 3020}, {2900, 2601, 574, 2709, 4331, 3028, 3653, 612}, {3143, 2900, 3653, 3020, 2601, 612, 144, 574}, {3028, 3687, 749, 4331, 3486, 3338, 2709, 3479}, {3687, 3486, 3479, 144, 3020, 3143, 749, 3338}, {749, 3479, 2601, 3028, 3338, 144, 2900, 4331}, {4331, 144, 3028, 3479, 3653, 3486, 612, 3687}, {3486, 3020, 3338, 3653, 2709, 2900, 3479, 3143}, {3338, 3143, 144, 3486, 2900, 574, 4331, 3653}, {2709, 749, 2900, 612, 3479, 4331, 3143, 2601}, {3479, 3338, 4331, 3687, 3143, 3653, 2601, 144}, {4097, 4368, 21555, 20699, 21612, 5346, 24881, 19335}, {1028, 26073, 26316, 23825, 4097, 21555, 21612, 24881}, {4368, 21612, 19335, 18564, 26316, 24831, 21555, 5346}, {18564, 30912, 4368, 5346, 1028, 26316, 4097, 21612}, {21555, 19335, 22433, 4097, 5346, 18564, 23825, 20699}, {26073, 4097, 24881, 22433, 4368, 19335, 26316, 21555}, {20699, 18564, 4097, 19335, 30912, 21612, 26073, 4368}, {22433, 20699, 26073, 21555, 18564, 4368, 1028, 4097}, {21612, 26316, 5346, 30912, 24881, 23825, 19335, 24831}, {26316, 24881, 24831, 1028, 21555, 22433, 5346, 23825}, {5346, 24831, 18564, 21612, 23825, 1028, 20699, 30912}, {30912, 1028, 21612, 24831, 26073, 24881, 4368, 26316}, {24881, 21555, 23825, 26073, 19335, 20699, 24831, 22433}, {23825, 22433, 1028, 24881, 20699, 4097, 30912, 26073}, {19335, 5346, 20699, 4368, 24831, 30912, 22433, 18564}, {24831, 23825, 30912, 26316, 22433, 26073, 18564, 1028}
};

int16x8_t twist64_inv_x1[32] = {
    {3479, 574, 612, 3020, 2900, 3028, 749, 3486}, {2709, 144, 3653, 3687, 3338, 574, 3020, 3028}, {3338, 612, 3028, 2709, 2601, 3687, 3479, 3020}, {3486, 2601, 4331, 612, 749, 144, 3687, 574}, {4331, 3020, 2709, 3143, 574, 749, 2601, 3338}, {749, 3653, 574, 3486, 3143, 612, 2709, 3687}, {3687, 2900, 2601, 574, 2709, 4331, 3028, 3653}, {3028, 3143, 2900, 3653, 3020, 2601, 612, 144}, {3143, 3028, 3687, 749, 4331, 3486, 3338, 2709}, {2900, 3687, 3486, 3479, 144, 3020, 3143, 749}, {3653, 749, 3479, 2601, 3028, 3338, 144, 2900}, {3020, 4331, 144, 3028, 3479, 3653, 3486, 612}, {2601, 3486, 3020, 3338, 3653, 2709, 2900, 3479}, {612, 3338, 3143, 144, 3486, 2900, 574, 4331}, {144, 2709, 749, 2900, 612, 3479, 4331, 3143}, {574, 3479, 3338, 4331, 3687, 3143, 3653, 2601}, {24831, 4097, 4368, 21555, 20699, 21612, 5346, 24881}, {19335, 1028, 26073, 26316, 23825, 4097, 21555, 21612}, {23825, 4368, 21612, 19335, 18564, 26316, 24831, 21555}, {24881, 18564, 30912, 4368, 5346, 1028, 26316, 4097}, {30912, 21555, 19335, 22433, 4097, 5346, 18564, 23825}, {5346, 26073, 4097, 24881, 22433, 4368, 19335, 26316}, {26316, 20699, 18564, 4097, 19335, 30912, 21612, 26073}, {21612, 22433, 20699, 26073, 21555, 18564, 4368, 1028}, {22433, 21612, 26316, 5346, 30912, 24881, 23825, 19335}, {20699, 26316, 24881, 24831, 1028, 21555, 22433, 5346}, {26073, 5346, 24831, 18564, 21612, 23825, 1028, 20699}, {21555, 30912, 1028, 21612, 24831, 26073, 24881, 4368}, {18564, 24881, 21555, 23825, 26073, 19335, 20699, 24831}, {4368, 23825, 22433, 1028, 24881, 20699, 4097, 30912}, {1028, 19335, 5346, 20699, 4368, 24831, 30912, 22433}, {4097, 24831, 23825, 30912, 26316, 22433, 26073, 18564}
};

int16x8_t twist64_inv_x2[32] = {
    {3338, 3479, 574, 612, 3020, 2900, 3028, 749}, {749, 2709, 144, 3653, 3687, 3338, 574, 3020}, {3143, 3338, 612, 3028, 2709, 2601, 3687, 3479}, {3020, 3486, 2601, 4331, 612, 749, 144, 3687}, {144, 4331, 3020, 2709, 3143, 574, 749, 2601}, {3479, 749, 3653, 574, 3486, 3143, 612, 2709}, {3486, 3687, 2900, 2601, 574, 2709, 4331, 3028}, {3687, 3028, 3143, 2900, 3653, 3020, 2601, 612}, {2900, 3143, 3028, 3687, 749, 4331, 3486, 3338}, {2601, 2900, 3687, 3486, 3479, 144, 3020, 3143}, {574, 3653, 749, 3479, 2601, 3028, 3338, 144}, {2709, 3020, 4331, 144, 3028, 3479, 3653, 3486}, {4331, 2601, 3486, 3020, 3338, 3653, 2709, 2900}, {3028, 612, 3338, 3143, 144, 3486, 2900, 574}, {3653, 144, 2709, 749, 2900, 612, 3479, 4331}, {612, 574, 3479, 3338, 4331, 3687, 3143, 3653}, {23825, 24831, 4097, 4368, 21555, 20699, 21612, 5346}, {5346, 19335, 1028, 26073, 26316, 23825, 4097, 21555}, {22433, 23825, 4368, 21612, 19335, 18564, 26316, 24831}, {21555, 24881, 18564, 30912, 4368, 5346, 1028, 26316}, {1028, 30912, 21555, 19335, 22433, 4097, 5346, 18564}, {24831, 5346, 26073, 4097, 24881, 22433, 4368, 19335}, {24881, 26316, 20699, 18564, 4097, 19335, 30912, 21612}, {26316, 21612, 22433, 20699, 26073, 21555, 18564, 4368}, {20699, 22433, 21612, 26316, 5346, 30912, 24881, 23825}, {18564, 20699, 26316, 24881, 24831, 1028, 21555, 22433}, {4097, 26073, 5346, 24831, 18564, 21612, 23825, 1028}, {19335, 21555, 30912, 1028, 21612, 24831, 26073, 24881}, {30912, 18564, 24881, 21555, 23825, 26073, 19335, 20699}, {21612, 4368, 23825, 22433, 1028, 24881, 20699, 4097}, {26073, 1028, 19335, 5346, 20699, 4368, 24831, 30912}, {4368, 4097, 24831, 23825, 30912, 26316, 22433, 26073}
};


void polymul_64x64_rader_in(int16x8_t* a_out, int16x8_t* b_out, int16x8_t* a, int16x8_t* b){
    //Rader17: 8x1 = 8
    __truncated_rader17_64(a_out, a, &twiddle_p_64, &twiddle_n_64, twist64);
    __truncated_rader17_64(b_out, b, &twiddle_p_64, &twiddle_n_64, twist64);
}

void polymul_64x64_rader_8x8(int16x8_t* c, int16x8_t* a, int16x8_t* b){       
    __rader8x8p(c, a, b);
    __rader8x8p(c+8, a+8, b+8);
}

void polymul_64x64_rader_8x8_x1(int16x8_t* c, int16x8_t* a, int16x8_t* b){       
    __rader8x8p_x1(c, a, b);
    __rader8x8p_x1(c+8, a+8, b+8);
}

void polymul_64x64_rader_8x8_x2(int16x8_t* c, int16x8_t* a, int16x8_t* b){       
    __rader8x8p_x2(c, a, b);
    __rader8x8p_x2(c+8, a+8, b+8);
}

void polymul_64x64_rader_out(int16x8_t* c, int16x8_t* c_in){    
    __itruncated_rader_17_64(c, c_in, &itwiddle_p_64, &itwiddle_n_64, twist64_inv);
}

void polymul_64x64_rader_out_x1(int16x8_t* c, int16x8_t* c_in){    
    __itruncated_rader_17_64(c, c_in, &itwiddle_p_64, &itwiddle_n_64, twist64_inv_x1);
}

void polymul_64x64_rader_out_x2(int16x8_t* c, int16x8_t* c_in){    
    __itruncated_rader_17_64(c, c_in, &itwiddle_p_64, &itwiddle_n_64, twist64_inv_x2);
}

void polymul_64x64_truncated_rader17(int16x8_t *c, int16x8_t *a, int16x8_t *b){
    int16x8_t NTT_a[16], NTT_b[16], NTT_c[16];
    polymul_64x64_rader_in(NTT_a, NTT_b, a, b);
    polymul_64x64_rader_8x8(NTT_c, NTT_a, NTT_b);
    polymul_64x64_rader_out(c, NTT_c);
}

// ----------------------------------------------------------

void polymul_64x64_karatsuba(int16x8_t *c, const int16x8_t *a, const int16x8_t *b)
{
    int16x8_t stmp[8] = {0}, tmp_a[4] = {0}, tmp_b[4] = {0};
    // high & low term
    polymul_32x32_karatsuba(c, a, b);
    polymul_32x32_karatsuba(c+8, a+4, b+4);
    
    // middle term
    for (int i = 0; i < 4; i++)
    {
        tmp_a[i] = barrett_fake(vaddq_s16(a[i], a[i + 4]));
        tmp_b[i] = barrett_fake(vaddq_s16(b[i], b[i + 4]));
    }
    polymul_32x32_karatsuba(stmp, tmp_a, tmp_b);
    
    for (int i = 0; i < 4; i++)
    {
        c[i+4] = vsubq_s16(c[i+4], c[i+8]);
        c[i+8] = barrett_fake(vsubq_s16(stmp[i+4], vaddq_s16(c[i+4], c[i+12])));
        c[i+4] = barrett_fake(vaddq_s16(c[i+4], vsubq_s16(stmp[i], c[i])));
    }
}


// ----------------------------------------------------------

void polymul_64x64_Toom_InputTransform(int16x8_t *c, const int16x8_t *a)
{
    //Input
    int16x8_t odd[4] = {0}, even[4] = {0};
    for (int i = 0; i < 2; i++)
    {
        // 0
        c[i] = a[i];

        // 00
        c[i+6] = a[i+6];

        // even/odd: 1, -1, 2, -2
        even[i] = vaddq_s16(a[i], a[i+4]);
        odd[i] = vaddq_s16(a[i+2], a[i+6]);
        even[i+2] = barrett_mla_4(a[i], a[i+4]);
        odd[i+2] = barrett_mla_8(barrett_mla_2(odd[i+2], a[i+2]), a[i+6]);
        
        // 4
        c[i+12] = barrett_mla_64(barrett_mla_16(barrett_mla_4(a[i], a[i+2]), a[i+4]), a[i+6]);
    }

    for (int i=0; i<2; i++){
        //1, -1
        c[i+2]  =  barrett_fake(vaddq_s16(even[i], odd[i]));
        c[i+8]  =  barrett_fake(vsubq_s16(even[i], odd[i])); 
        //2, -2
        c[i+4]  =  barrett_fake(vaddq_s16(even[i+2], odd[i+2]));
        c[i+10] =  barrett_fake(vsubq_s16(even[i+2], odd[i+2]));
    }
}


void polymul_64x64_Toom_Output(int16x8_t *c, int16x8x4_t *h)
{
    int16x8_t cx[28] = {0};
    for(int i = 0;i<4;i++){
        cx[i] = h[0].val[i];

        cx[4+i] = barrett_mla_3443(cx[4+i], h[0].val[i]);
        cx[4+i] = barrett_mla_511(cx[4+i], h[1].val[i]);
        cx[4+i] = barrett_mla_765(cx[4+i], h[2].val[i]);
        cx[4+i] = barrett_mla_4575(cx[4+i], h[3].val[i]);
        cx[4+i] = barrett_mla_2448(cx[4+i], h[4].val[i]);
        cx[4+i] = barrett_mla_4336(cx[4+i], h[5].val[i]);
        cx[4+i] = barrett_mla_2270(cx[4+i], h[6].val[i]);

        cx[8+i] = barrett_mla_3442(cx[8+i], h[0].val[i]);
        cx[8+i] = barrett_mla_1531(cx[8+i], vaddq_s16(h[1].val[i],  h[4].val[i]));
        cx[8+i] = barrett_mla_1339(cx[8+i], vaddq_s16(h[2].val[i], h[5].val[i]));
        cx[8+i] = barrett_mla_4(cx[8+i], h[3].val[i]);

        cx[12+i] = barrett_mla_1435(cx[12+i], h[0].val[i]);
        cx[12+i] = barrett_mla_2040(cx[12+i], h[1].val[i]);
        cx[12+i] = barrett_mla_861(cx[12+i], h[2].val[i]);
        cx[12+i] = barrett_mla_20(cx[12+i], h[3].val[i]);
        cx[12+i] = barrett_mla_797(cx[12+i], h[5].val[i]);
        cx[12+i] = barrett_mla_4049(cx[12+i], h[6].val[i]);

        cx[16+i] = barrett_mla_1148(cx[16+i], h[0].val[i]);
        cx[16+i] = barrett_mla_765(cx[16+i], vaddq_s16(h[1].val[i], h[4].val[i]));
        cx[16+i] = barrett_mla_3252(cx[16+i], vaddq_s16(h[2].val[i],h[5].val[i]));
        cx[16+i] = barrett_mla_4586(cx[16+i], h[3].val[i]);

        cx[20+i] = barrett_mla_4304(cx[20+i], h[0].val[i]);
        cx[20+i] = barrett_mla_4336(cx[20+i], h[1].val[i]);
        cx[20+i] = barrett_mla_2965(cx[20+i], h[2].val[i]);
        cx[20+i] = barrett_mla_4587(cx[20+i], h[3].val[i]);
        cx[20+i] = barrett_mla_4438(cx[20+i], h[4].val[i]);
        cx[20+i] = barrett_mla_4049(cx[20+i], h[5].val[i]);
        cx[20+i] = barrett_mla_2863(cx[20+i], h[6].val[i]);
        
        cx[24+i] = h[3].val[i];
    }
    
    for (int i = 0; i < 7; i++)
    {
        for (int j = 0; j < 4; j++)
        {
            c[(i * 2) + j] = barrett_fake(vaddq_s16(c[(i * 2) + j], cx[(i * 4) + j]));
        }
    }
}

// ----------------------------------------------------------

void polymul_64x64_schoolbook(int16x8_t *c, const int16x8_t *a, const int16x8_t *b)
{
    int16x8_t c1[4][8];
    polymul_32x32(c1[0], a, b);
    polymul_32x32(c1[1], a, b+4);
    polymul_32x32(c1[2], a+4, b);
    polymul_32x32(c1[3], a+4, b+4);
    for(int i = 0;i<4;i++){
        c[i] = c1[0][i];
        c[i+4] = barrett_fake(c1[0][i+4] + c1[1][i] + c1[2][i]);
        c[i+8] = barrett_fake(c1[3][i] + c1[1][i+4] + c1[2][i+4]);
        c[i+12] = c1[3][i+4];
    }
}

// ------------------------------------------------------------

void polymul_64x64_Schonhage(int16x8_t *c, const int16x8_t *a, const int16x8_t *b)
{
    //(x^128-1) -> (y^16-1)(x^8-y)
    int16x8_t atmp[32] = {0}, btmp[32] = {0};
    int16x8_t aIn[32] = {0}, bIn[32] = {0}, cOut[64]= {0};
    permutation_64(atmp, a);
    permutation_64(btmp, b);

    //Input Transformation
    SchonhageIn_64(aIn, atmp);
    SchonhageIn_64(bIn, btmp);

    //Mul 16_16x16
    SchonhageMul_64(cOut, aIn, bIn);

    //Output Transformation
    SchonhageOut_64(c, cOut);
}

void permutation_64(int16x8_t* out, const int16x8_t* in)
{
    for (int i=0; i<8; i++){
        out[i*2] = in[i];
    }
}

void SchonhageIn_64(int16x8_t* out, int16x8_t* in)
{
    int16x8_t tmp[32] = {0};
    //x^16 = -1
    //(y^16-1) = (y^8-1)(y^8+1)
    //========Do nothing========

    //(y^8-1)(y^8+1) = (y^4-1)(y^4+1)(y^4-x^8)(y^4+x^8)
    for (int i=0; i<4; i++){
        //(y^8-1) -> (y^4-1)(y^4+1)
        tmp[i*2]   = barrett_fake(vaddq_s16(in[i*2], in[i*2+8])); 
        tmp[i*2+8] = barrett_fake(vsubq_s16(in[i*2], in[i*2+8]));
        //(y^8+1) -> (y^4-x^8)(y^4+x^8)
    }

    //(y^4-1)(y^4+1)(y^4-x^8)(y^4+x^8) = (y^2-1)(y^2+1)(y^2-x^8)(y^2+x^8)(y^2-x^4)(y^2+x^4)(y^2-x^12)(y^2+x^12)
    for (int i=0; i<2; i++){
        //(y^4-x^8) -> (y^2-x^4)(y^2+x^4)    
        in[i*2+16] = vaddq_s16(in[i*2], vextq_s16(vnegq_s16(in[i*2+12]), in[i*2+4], 4));
        in[i*2+17] = vaddq_s16(in[i*2+8], vextq_s16(in[i*2+4], in[i*2+12], 4));
        in[i*2+20] = vsubq_s16(in[i*2], vextq_s16(vnegq_s16(in[i*2+12]), in[i*2+4], 4));
        in[i*2+21] = vsubq_s16(in[i*2+8], vextq_s16(in[i*2+4], in[i*2+12], 4));
        //(y^4+x^8) -> (y^2-x^12)(y^2+x^12)
        in[i*2+24] = in[i*2] - vextq_s16(in[i*2+4], vnegq_s16(in[i*2+12]), 4);
        in[i*2+25] = vextq_s16(in[i*2+12], in[i*2+4], 4) - in[i*2+8];
        in[i*2+28] = in[i*2] + vextq_s16(in[i*2+4], vnegq_s16(in[i*2+12]), 4);
        in[i*2+29] = vnegq_s16(vextq_s16(in[i*2+12], in[i*2+4], 4) + in[i*2+8]) ;

        //(y^4-1)   -> (y^2-1)(y^2+1)
        in[i*2]   = vaddq_s16(tmp[i*2], tmp[i*2+4]);
        in[i*2+4] = vsubq_s16(tmp[i*2], tmp[i*2+4]);
        //(y^4+1)   -> (y^2-x^8)(y^2+x^8)
    }
    
    //(y^2-1)(y^2+1)(y^2-x^8)(y^2+x^8)(y^2-x^4)(y^2+x^4)(y^2-x^12)(y^2+x^12)
    //(y^2-1)    -> (y-1)(y+1)
    out[0] = (in[0] + in[2]);
    out[2] = (in[0] - in[2]);
    out[1] = out[3] = v0;
    //(y^2+1)    -> (y-x^8)(y+x^8)W
    out[4]  = out[6] = in[4];
    out[5]  = in[6];
    out[7]  = vnegq_s16(in[6]);
    //(y^2-x^8)  -> (y-x^4)(y+x^4)
    out[8]  = (vaddq_s16(tmp[8], vextq_s16(vnegq_s16(tmp[14]), tmp[10], 4)));
    out[9]  = (vaddq_s16(tmp[12], vextq_s16(tmp[10], tmp[14], 4)));
    out[10] = (vsubq_s16(tmp[8], vextq_s16(vnegq_s16(tmp[14]), tmp[10], 4)));
    out[11] = (vsubq_s16(tmp[12], vextq_s16(tmp[10], tmp[14], 4)));
    //(y^2+x^8)  -> (y-x^12)(y+x^12)
    out[12] = (vsubq_s16(tmp[8], vextq_s16(tmp[10], vnegq_s16(tmp[14]), 4)));
    out[13] = (vaddq_s16(vnegq_s16(tmp[12]), vextq_s16(tmp[14], tmp[10], 4)));
    out[14] = (vaddq_s16(tmp[8], vextq_s16(tmp[10], vnegq_s16(tmp[14]), 4)));
    out[15] = (vsubq_s16(vnegq_s16(tmp[12]), vextq_s16(tmp[14], tmp[10], 4)));
    //(y^2-x^4)  -> (y-x^2)(y+x^2)
    out[16] = (vaddq_s16(in[16], vextq_s16(vnegq_s16(in[19]), in[18], 6)));
    out[17] = (vaddq_s16(in[17], vextq_s16(in[18], in[19], 6)));
    out[18] = (vsubq_s16(in[16], vextq_s16(vnegq_s16(in[19]), in[18], 6)));
    out[19] = (vsubq_s16(in[17], vextq_s16(in[18], in[19], 6)));
    //(y^2+x^4)  -> (y-x^10)(y+x^10)
    out[20] = (vsubq_s16(in[20], vextq_s16(in[22], in[23], 6)));
    out[21] = (vaddq_s16(in[21], vextq_s16(vnegq_s16(in[23]), in[22], 6)));
    out[22] = (vaddq_s16(in[20], vextq_s16(in[22], in[23], 6)));
    out[23] = (vsubq_s16(in[21], vextq_s16(vnegq_s16(in[23]), in[22], 6)));
    //(y^2-x^12) -> (y-x^6)(y+x^6)
    out[24] = (vaddq_s16(in[24], vextq_s16(vnegq_s16(in[27]), in[26], 2)));
    out[25] = (vaddq_s16(in[25], vextq_s16(in[26], in[27], 2)));
    out[26] = (vsubq_s16(in[24], vextq_s16(vnegq_s16(in[27]), in[26], 2)));
    out[27] = (vsubq_s16(in[25], vextq_s16(in[26], in[27], 2)));
    //(y^2+x^12) -> (y-x^14)(y+x^14)
    out[28] = (vsubq_s16(in[28], vextq_s16(in[30], in[31], 2)));
    out[29] = (vaddq_s16(in[29], vextq_s16(vnegq_s16(in[31]), in[30], 2)));
    out[30] = (vaddq_s16(in[28], vextq_s16(in[30], in[31], 2)));
    out[31] = (vsubq_s16(in[29], vextq_s16(vnegq_s16(in[31]), in[30], 2)));
}

void SchonhageMul_64(int16x8_t* c, int16x8_t* a, int16x8_t* b)
{
    //16_16x16 -> (8_32, 8_32)
    int16x8_t res[64], tmpa[56] = {0}, tmpb[56] = {0};
    __asm8_16x16(res, a, b, tmpa);
    __asm8_16x16(res+32, a+16, b+16, tmpb);

    //mod (x^16+1)
    for (int i=0; i<16; i++){
        c[i*2] = res[i*4] - res[i*4+2];
        c[i*2+1] = res[i*4+1] - res[i*4+3];
    }
}

void SchonhageOut_64(int16x8_t* out, int16x8_t* in)
{
    int16x8_t tmp[32] = {0};
    //(y-1)(y+1)(y-x^8)(y+x^8)(y-x^4)(y+x^4)(y-x^12)(y+x^12)(y-x^2)(y+x^2)(y-x^10)(y+x^10)(y-x^6)(y+x^6)(y-x^14)(y+x^14)
    //(y-1)(y+1) -> (y^2-1)
    for (int i=0; i<2; i++){
        tmp[i]   = vaddq_s16(in[i], in[i+2]);
        tmp[i+2] = vsubq_s16(in[i], in[i+2]);
    }
    //(y-x^8)(y+x^8)   -> (y^2+1)
    tmp[4] = vaddq_s16(in[4], in[6]);
    tmp[5] = vaddq_s16(in[5], in[7]);
    tmp[6] = vsubq_s16(in[5], in[7]);
    tmp[7] = vsubq_s16(in[6], in[4]);
    //(y-x^4)(y+x^4)   -> (y^2-x^8)
    tmp[8]  = vaddq_s16(in[8], in[10]);
    tmp[9]  = vaddq_s16(in[9], in[11]);
    tmp[10] = vsubq_s16(vextq_s16(in[8], in[9], 4), vextq_s16(in[10], in[11], 4));
    tmp[11] = vsubq_s16(vextq_s16(in[9], vnegq_s16(in[8]), 4), vextq_s16(in[11], vnegq_s16(in[10]), 4));
    //(y-x^12)(y+x^12) -> (y^2+x^8)
    tmp[12] = vaddq_s16(in[12], in[14]);
    tmp[13] = vaddq_s16(in[13], in[15]);
    tmp[14] = vsubq_s16(vextq_s16(in[13], vnegq_s16(in[12]), 4), vextq_s16(in[15], vnegq_s16(in[14]), 4));
    tmp[15] = vsubq_s16(vextq_s16(in[14], in[15], 4), vextq_s16(in[12], in[13], 4));
    //(y-x^2)(y+x^2)   -> (y^2-x^4)
    tmp[16] = vaddq_s16(in[16], in[18]);
    tmp[17] = vaddq_s16(in[17], in[19]);
    tmp[18] = vsubq_s16(vextq_s16(in[16], in[17], 2), vextq_s16(in[18], in[19], 2));
    tmp[19] = vsubq_s16(vextq_s16(in[17], vnegq_s16(in[16]), 2), vextq_s16(in[19], vnegq_s16(in[18]), 2));
    //(y-x^10)(y+x^10) -> (y^2+x^4)
    tmp[20] = vaddq_s16(in[20], in[22]);
    tmp[21] = vaddq_s16(in[21], in[23]);
    tmp[22] = vsubq_s16(vextq_s16(in[21], vnegq_s16(in[20]), 2), vextq_s16(in[23], vnegq_s16(in[22]), 2));
    tmp[23] = vsubq_s16(vextq_s16(in[22], in[23], 2), vextq_s16(in[20], in[21], 2));
    //(y-x^6)(y+x^6)   -> (y^2-x^12)
    tmp[24] = vaddq_s16(in[24], in[26]);
    tmp[25] = vaddq_s16(in[25], in[27]);
    tmp[26] = vsubq_s16(vextq_s16(in[24], in[25], 6), vextq_s16(in[26], in[27], 6));
    tmp[27] = vsubq_s16(vextq_s16(in[25], vnegq_s16(in[24]), 6), vextq_s16(in[27], vnegq_s16(in[26]), 6));
    //(y-x^14)(y+x^14) -> (y^2+x^12)
    tmp[28] = vaddq_s16(in[28], in[30]);
    tmp[29] = vaddq_s16(in[29], in[31]);
    tmp[30] = vsubq_s16(vextq_s16(in[29], vnegq_s16(in[28]), 6), vextq_s16(in[31], vnegq_s16(in[30]), 6));
    tmp[31] = vsubq_s16(vextq_s16(in[30], in[31], 6), vextq_s16(in[28], in[29], 6));
    
    //(y^2-1)(y^2+1)(y^2-x^8)(y^2+x^8)(y^2-x^4)(y^2+x^4)(y^2-x^12)(y^2+x^12)
    //(y^2-1)(y^2+1) -> (y^4-1)
    for (int i=0; i<4; i++){
        in[i]   = tmp[i] + tmp[i+4];
        in[i+4] = tmp[i] - tmp[i+4]; 
    }
    //(y^2-x^8)(y^2+x^8)   -> (y^4+1)
    for (int i=8; i<12; i++){
        in[i] = tmp[i] + tmp[i+4];
    }
    in[12] = tmp[9]  - tmp[13]; 
    in[13] = tmp[12] - tmp[8];
    in[14] = tmp[11] - tmp[15]; 
    in[15] = tmp[14] - tmp[10];
    //(y^2-x^4)(y^2+x^4)   -> (y^4-x^8)
    for (int i=16; i<20; i++){
        in[i] = tmp[i] + tmp[i+4];
    }
    in[20] = vextq_s16(tmp[16], tmp[17], 4) - vextq_s16(tmp[20], tmp[21], 4);
    in[21] = vextq_s16(tmp[17], vnegq_s16(tmp[16]), 4) - vextq_s16(tmp[21], vnegq_s16(tmp[20]), 4);
    in[22] = vextq_s16(tmp[18], tmp[19], 4) - vextq_s16(tmp[22], tmp[23], 4);
    in[23] = vextq_s16(tmp[19], vnegq_s16(tmp[18]), 4) - vextq_s16(tmp[23], vnegq_s16(tmp[22]), 4);
    //(y^2-x^12)(y^2+x^12) -> (y^4+x^8)
    for (int i=24; i<28; i++){
        in[i] = tmp[i] + tmp[i+4];
    }
    in[28] = vextq_s16(tmp[25], vnegq_s16(tmp[24]), 4) - vextq_s16(tmp[29], vnegq_s16(tmp[28]), 4); 
    in[29] = vextq_s16(tmp[28], tmp[29], 4) - vextq_s16(tmp[24], tmp[25], 4);
    in[30] = vextq_s16(tmp[27], vnegq_s16(tmp[26]), 4) - vextq_s16(tmp[31], vnegq_s16(tmp[30]), 4); 
    in[31] = vextq_s16(tmp[30], tmp[31], 4) - vextq_s16(tmp[26], tmp[27], 4);

    //(y^4-1)(y^4+1)(y^4-x^8)(y^4+x^8)
    //(y^4-1)(y^4+1) -> (y^8-1)
    for (int i=0; i<8; i++){
        tmp[i]   = barrett_fake(in[i] + in[i+8]);
        tmp[i+8] = barrett_fake(in[i] - in[i+8]);
    }
    //(y^4-x^8)(y^4+x^8) -> (y^8+1)
    for (int i=16; i<24; i++){
        tmp[i] = barrett_fake(in[i] + in[i+8]);
    }
    for (int i=0; i<4; i++){
        tmp[24+i*2] = barrett_fake(in[17+i*2] - in[25+i*2]);
        tmp[25+i*2] = barrett_fake(in[24+i*2] - in[16+i*2]);
    }

    //(y^8-1)(y^8+1)
    //(y^8-1)(y^8+1) ->(y^16-1)
    for (int i=0; i<16; i++){
        in[i] = (tmp[i] + tmp[i+16]);
        in[i+16] = (tmp[i] - tmp[i+16]);
    }

    //y = x^8 and 1/16
    out[0] = innerProduct_287(in[0] - in[31]);
    for (int i=0; i<15; i++){
        out[i+1] = innerProduct_287(in[i*2+1] + in[i*2+2]);
    }
}